{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/b1/wt2bjx71325fk62cxg92dwl80000gn/T/tmp0rwpu8n9.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import tempfile\n",
    "\n",
    "data_url = \"https://gist.githubusercontent.com/serranoarevalo/5acf755c2b8d83f1707ef266b82ea223/raw/d72b9558a11523adbe13300b41321ecd93d331d3/document.txt\"\n",
    "\n",
    "response = requests.get(data_url)\n",
    "\n",
    "with tempfile.NamedTemporaryFile(delete=False, suffix=\".txt\") as temp_file:\n",
    "    temp_file.write(response.content)\n",
    "    temp_file_path = temp_file.name\n",
    "    \n",
    "print(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "cache_dir = LocalFileStore(\"./.cache/\")\n",
    "\n",
    "splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=600,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=80,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "loader = UnstructuredFileLoader(file_path=temp_file_path)\n",
    "docs = loader.load_and_split(text_splitter=splitter)\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "cached_embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    embeddings, cache_dir\n",
    ")\n",
    "vectorstore = FAISS.from_documents(docs, cached_embeddings)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer questions using only the following context. If you don't know the answer just say you don't know, don't make it up:\\n\\n{context}\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "chain = ({\n",
    "            \"context\": retriever, \n",
    "            \"question\": RunnablePassthrough(),\n",
    "        } \n",
    "         | prompt \n",
    "         | llm\n",
    ")\n",
    "\n",
    "def get_cache_data(question):\n",
    "    loaded_data = load_memory(_)\n",
    "    print(loaded_data)\n",
    "    for i in range(0, len(loaded_data), 2):\n",
    "        human = loaded_data[i]\n",
    "        if human.content == question:\n",
    "            hit = loaded_data[i + 1]\n",
    "            print(\"memory history hit!!!\")\n",
    "            return hit \n",
    "    return None\n",
    "    \n",
    "def invoke_chain(question):\n",
    "    result = get_cache_data(question)\n",
    "    if result is None:\n",
    "        result = chain.invoke(question)\n",
    "        memory.save_context(\n",
    "            {\"input\": question},\n",
    "            {\"output\": result.content},\n",
    "        )\n",
    "    print(\"[Answer]\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[Answer] content=\"According to the context, Winston believes that Aaronson, along with Jones and Rutherford, were guilty of the crimes they were charged with, despite having a memory that disproved their guilt. He concludes that he had never seen the photograph that disproved their guilt and that it had never existed, indicating that he accepted the Party's narrative.\" response_metadata={'token_usage': <OpenAIObject at 0x313c587d0> JSON: {\n",
      "  \"prompt_tokens\": 2333,\n",
      "  \"completion_tokens\": 67,\n",
      "  \"total_tokens\": 2400\n",
      "}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None} id='run-82481185-8be9-48a6-90f1-d6609085708e-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Is Aaronson guilty?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Is Aaronson guilty?'), AIMessage(content=\"According to the context, Winston believes that Aaronson, along with Jones and Rutherford, were guilty of the crimes they were charged with, despite having a memory that disproved their guilt. He concludes that he had never seen the photograph that disproved their guilt and that it had never existed, indicating that he accepted the Party's narrative.\")]\n",
      "[Answer] content='He traced with his finger in the dust on the table: 2+2=5.' response_metadata={'token_usage': <OpenAIObject at 0x3121a36b0> JSON: {\n",
      "  \"prompt_tokens\": 2318,\n",
      "  \"completion_tokens\": 19,\n",
      "  \"total_tokens\": 2337\n",
      "}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None} id='run-e6fa2680-c7a4-4020-979d-ac59006eb7fb-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"What message did he write on the table?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='Is Aaronson guilty?'), AIMessage(content=\"According to the context, Winston believes that Aaronson, along with Jones and Rutherford, were guilty of the crimes they were charged with, despite having a memory that disproved their guilt. He concludes that he had never seen the photograph that disproved their guilt and that it had never existed, indicating that he accepted the Party's narrative.\"), HumanMessage(content='What message did he write on the table?'), AIMessage(content='He traced with his finger in the dust on the table: 2+2=5.')]\n",
      "[Answer] content='Julia is a character who is loved by the protagonist, Winston. In the context provided, Winston experiences a strong emotional connection to her, feeling that he loves her more in his memories than when they were together and free. She is also someone he wishes to protect from punishment during a moment of weakness.' response_metadata={'token_usage': <OpenAIObject at 0x317c919d0> JSON: {\n",
      "  \"prompt_tokens\": 2186,\n",
      "  \"completion_tokens\": 60,\n",
      "  \"total_tokens\": 2246\n",
      "}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f33667828e', 'finish_reason': 'stop', 'logprobs': None} id='run-40ce70cb-01d7-4966-8b76-78d4443b910a-0'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Who is Julia?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
